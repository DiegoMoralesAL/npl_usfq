{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiCDtW2w-hyf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "epochs = 15"
   ],
   "metadata": {
    "id": "m40zvNAEP_Id"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Remapear las categorías de sentimiento a tres categorías\n",
    "def simplify_sentiment(sentiment):\n",
    "    if sentiment in [0, 1]:\n",
    "        return 0  # Negative\n",
    "    elif sentiment == 2:\n",
    "        return 1  # Neutral\n",
    "    else:\n",
    "        return 2  # Positive"
   ],
   "metadata": {
    "id": "XG0opwdwYZ9m"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cargar el dataset desde un archivo .tsv\n",
    "data = pd.read_csv('train.tsv', sep='\\t')\n",
    "\n",
    "# Rellenar valores faltantes con un string vacío\n",
    "data['Phrase'] = data['Phrase'].fillna('')\n",
    "\n",
    "data['Sentiment'] = data['Sentiment'].apply(simplify_sentiment)\n",
    "\n",
    "# Separar datos en características y etiquetas\n",
    "X = data['Phrase']\n",
    "y = data['Sentiment']\n",
    "\n",
    "# Codificación de etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Tokenizar y preparar las secuencias\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_sequences = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(X_sequences, maxlen=100)\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba (estratificado)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=13)\n",
    "for train_index, test_index in sss.split(X_padded, y):\n",
    "    X_train, X_test = X_padded[train_index], X_padded[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba para Naive Bayes\n",
    "X_train_nb, X_test_nb, y_train_nb, y_test_nb = train_test_split(X, y, test_size=0.2, random_state=13, stratify=y)"
   ],
   "metadata": {
    "id": "UZmrX3dNOqHr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Función para construir modelos y entrenar\n",
    "def create_and_train_rnn_model(model_type, X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "\n",
    "    if model_type == 'RNN':\n",
    "        model.add(SimpleRNN(128))\n",
    "    elif model_type == 'LSTM':\n",
    "        model.add(LSTM(128))\n",
    "    elif model_type == 'GRU':\n",
    "        model.add(GRU(128))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax'))  # Tres categorías\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    print(f\"Confusion Matrix - {model_type}\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(f\"Classification Report - {model_type}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Calcular y retornar F1 Score\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"Weighted F1 Score - {model_type}: {f1:.4f}\")\n",
    "\n",
    "    return f1"
   ],
   "metadata": {
    "id": "6PtAt8lVOR26"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------\n",
    "# Implementación de Naive Bayes\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Crear el pipeline para el modelo de Naive Bayes\n",
    "naive_model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Entrenar el modelo Naive Bayes\n",
    "naive_model.fit(X_train_nb, y_train_nb)\n",
    "\n",
    "# Generar predicciones\n",
    "y_pred_nb = naive_model.predict(X_test_nb)\n",
    "\n",
    "# Evaluar el modelo Naive Bayes\n",
    "print(f\"Confusion Matrix - Naive Bayes\")\n",
    "print(confusion_matrix(y_test_nb, y_pred_nb))\n",
    "print(f\"Classification Report - Naive Bayes\")\n",
    "print(classification_report(y_test_nb, y_pred_nb))\n",
    "\n",
    "# Calcular F1 Score para Naive Bayes\n",
    "nb_f1 = f1_score(y_test_nb, y_pred_nb, average='weighted')\n",
    "print(f\"Weighted F1 Score - Naive Bayes: {nb_f1:.4f}\")\n",
    "\n",
    "# Entrenar y comparar los otros modelos\n",
    "rnn_f1 = create_and_train_rnn_model('RNN', X_train, y_train, X_test, y_test)\n",
    "lstm_f1 = create_and_train_rnn_model('LSTM', X_train, y_train, X_test, y_test)\n",
    "gru_f1 = create_and_train_rnn_model('GRU', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Comparar resultados\n",
    "results = {\n",
    "    \"RNN\": rnn_f1,\n",
    "    \"LSTM\": lstm_f1,\n",
    "    \"GRU\": gru_f1,\n",
    "    \"Naive Bayes\": nb_f1\n",
    "}\n",
    "\n",
    "best_model = max(results, key=results.get)\n",
    "print(f\"Best model is {best_model} with a weighted F1 score of {results[best_model]:.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXuMn9RKGWoQ",
    "outputId": "03011ffb-464a-421d-ee40-73ed25a069d3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix - Naive Bayes\n",
      "[[ 4237  2261   371]\n",
      " [ 1939 11519  2458]\n",
      " [  365  2424  5638]]\n",
      "Classification Report - Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63      6869\n",
      "           1       0.71      0.72      0.72     15916\n",
      "           2       0.67      0.67      0.67      8427\n",
      "\n",
      "    accuracy                           0.69     31212\n",
      "   macro avg       0.67      0.67      0.67     31212\n",
      "weighted avg       0.68      0.69      0.69     31212\n",
      "\n",
      "Weighted F1 Score - Naive Bayes: 0.6850\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m215s\u001B[0m 67ms/step - accuracy: 0.5929 - loss: 0.8954 - val_accuracy: 0.7173 - val_loss: 0.7000\n",
      "Epoch 2/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m258s\u001B[0m 66ms/step - accuracy: 0.7408 - loss: 0.6435 - val_accuracy: 0.7207 - val_loss: 0.6912\n",
      "Epoch 3/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m261s\u001B[0m 66ms/step - accuracy: 0.7689 - loss: 0.5748 - val_accuracy: 0.7385 - val_loss: 0.6570\n",
      "Epoch 4/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m256s\u001B[0m 64ms/step - accuracy: 0.7862 - loss: 0.5284 - val_accuracy: 0.7263 - val_loss: 0.7041\n",
      "Epoch 5/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m197s\u001B[0m 63ms/step - accuracy: 0.7994 - loss: 0.4940 - val_accuracy: 0.7299 - val_loss: 0.6873\n",
      "Epoch 6/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m202s\u001B[0m 63ms/step - accuracy: 0.8003 - loss: 0.4915 - val_accuracy: 0.7355 - val_loss: 0.6939\n",
      "Epoch 7/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m201s\u001B[0m 63ms/step - accuracy: 0.8201 - loss: 0.4443 - val_accuracy: 0.7315 - val_loss: 0.7115\n",
      "Epoch 8/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m194s\u001B[0m 62ms/step - accuracy: 0.8232 - loss: 0.4280 - val_accuracy: 0.7270 - val_loss: 0.7135\n",
      "Epoch 9/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m196s\u001B[0m 63ms/step - accuracy: 0.8339 - loss: 0.4045 - val_accuracy: 0.7354 - val_loss: 0.7526\n",
      "Epoch 10/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m204s\u001B[0m 63ms/step - accuracy: 0.8412 - loss: 0.3837 - val_accuracy: 0.7245 - val_loss: 0.7778\n",
      "Epoch 11/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m201s\u001B[0m 63ms/step - accuracy: 0.8441 - loss: 0.3741 - val_accuracy: 0.7279 - val_loss: 0.7767\n",
      "Epoch 12/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m204s\u001B[0m 64ms/step - accuracy: 0.8532 - loss: 0.3530 - val_accuracy: 0.7268 - val_loss: 0.8447\n",
      "Epoch 13/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m199s\u001B[0m 63ms/step - accuracy: 0.8598 - loss: 0.3372 - val_accuracy: 0.7236 - val_loss: 0.8216\n",
      "Epoch 14/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m202s\u001B[0m 63ms/step - accuracy: 0.8592 - loss: 0.3396 - val_accuracy: 0.7230 - val_loss: 0.8376\n",
      "Epoch 15/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m202s\u001B[0m 63ms/step - accuracy: 0.8681 - loss: 0.3182 - val_accuracy: 0.7210 - val_loss: 0.9128\n",
      "\u001B[1m976/976\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 14ms/step\n",
      "Confusion Matrix - RNN\n",
      "[[ 4714  1929   226]\n",
      " [ 2026 11969  1921]\n",
      " [  286  2278  5863]]\n",
      "Classification Report - RNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68      6869\n",
      "           1       0.74      0.75      0.75     15916\n",
      "           2       0.73      0.70      0.71      8427\n",
      "\n",
      "    accuracy                           0.72     31212\n",
      "   macro avg       0.71      0.71      0.71     31212\n",
      "weighted avg       0.72      0.72      0.72     31212\n",
      "\n",
      "Weighted F1 Score - RNN: 0.7223\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m656s\u001B[0m 209ms/step - accuracy: 0.6358 - loss: 0.8203 - val_accuracy: 0.7317 - val_loss: 0.6563\n",
      "Epoch 2/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m652s\u001B[0m 209ms/step - accuracy: 0.7594 - loss: 0.5886 - val_accuracy: 0.7428 - val_loss: 0.6327\n",
      "Epoch 3/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m684s\u001B[0m 210ms/step - accuracy: 0.7919 - loss: 0.5118 - val_accuracy: 0.7469 - val_loss: 0.6395\n",
      "Epoch 4/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m660s\u001B[0m 212ms/step - accuracy: 0.8143 - loss: 0.4552 - val_accuracy: 0.7456 - val_loss: 0.6623\n",
      "Epoch 5/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m682s\u001B[0m 211ms/step - accuracy: 0.8259 - loss: 0.4194 - val_accuracy: 0.7443 - val_loss: 0.6848\n",
      "Epoch 6/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m656s\u001B[0m 210ms/step - accuracy: 0.8384 - loss: 0.3841 - val_accuracy: 0.7362 - val_loss: 0.7350\n",
      "Epoch 7/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m661s\u001B[0m 212ms/step - accuracy: 0.8544 - loss: 0.3464 - val_accuracy: 0.7336 - val_loss: 0.7939\n",
      "Epoch 8/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m663s\u001B[0m 212ms/step - accuracy: 0.8641 - loss: 0.3196 - val_accuracy: 0.7304 - val_loss: 0.8570\n",
      "Epoch 9/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m681s\u001B[0m 212ms/step - accuracy: 0.8752 - loss: 0.2919 - val_accuracy: 0.7295 - val_loss: 0.9391\n",
      "Epoch 10/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m660s\u001B[0m 211ms/step - accuracy: 0.8853 - loss: 0.2686 - val_accuracy: 0.7231 - val_loss: 1.0099\n",
      "Epoch 11/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m682s\u001B[0m 211ms/step - accuracy: 0.8967 - loss: 0.2428 - val_accuracy: 0.7216 - val_loss: 1.0840\n",
      "Epoch 12/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m685s\u001B[0m 212ms/step - accuracy: 0.9051 - loss: 0.2212 - val_accuracy: 0.7201 - val_loss: 1.1883\n",
      "Epoch 13/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m664s\u001B[0m 213ms/step - accuracy: 0.9150 - loss: 0.2025 - val_accuracy: 0.7130 - val_loss: 1.2252\n",
      "Epoch 14/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m716s\u001B[0m 224ms/step - accuracy: 0.9229 - loss: 0.1836 - val_accuracy: 0.7117 - val_loss: 1.2993\n",
      "Epoch 15/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m709s\u001B[0m 213ms/step - accuracy: 0.9291 - loss: 0.1702 - val_accuracy: 0.7101 - val_loss: 1.3759\n",
      "\u001B[1m976/976\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m62s\u001B[0m 63ms/step\n",
      "Confusion Matrix - LSTM\n",
      "[[ 4445  2209   215]\n",
      " [ 1843 11932  2141]\n",
      " [  232  2308  5887]]\n",
      "Classification Report - LSTM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66      6869\n",
      "           1       0.73      0.75      0.74     15916\n",
      "           2       0.71      0.70      0.71      8427\n",
      "\n",
      "    accuracy                           0.71     31212\n",
      "   macro avg       0.71      0.70      0.70     31212\n",
      "weighted avg       0.71      0.71      0.71     31212\n",
      "\n",
      "Weighted F1 Score - LSTM: 0.7128\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m565s\u001B[0m 180ms/step - accuracy: 0.6407 - loss: 0.8131 - val_accuracy: 0.7290 - val_loss: 0.6573\n",
      "Epoch 2/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m577s\u001B[0m 185ms/step - accuracy: 0.7625 - loss: 0.5800 - val_accuracy: 0.7431 - val_loss: 0.6339\n",
      "Epoch 3/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m606s\u001B[0m 180ms/step - accuracy: 0.7923 - loss: 0.5090 - val_accuracy: 0.7414 - val_loss: 0.6404\n",
      "Epoch 4/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m561s\u001B[0m 180ms/step - accuracy: 0.8118 - loss: 0.4600 - val_accuracy: 0.7457 - val_loss: 0.6498\n",
      "Epoch 5/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m579s\u001B[0m 185ms/step - accuracy: 0.8269 - loss: 0.4198 - val_accuracy: 0.7435 - val_loss: 0.6703\n",
      "Epoch 6/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m621s\u001B[0m 185ms/step - accuracy: 0.8407 - loss: 0.3835 - val_accuracy: 0.7377 - val_loss: 0.7212\n",
      "Epoch 7/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m605s\u001B[0m 180ms/step - accuracy: 0.8555 - loss: 0.3469 - val_accuracy: 0.7322 - val_loss: 0.7540\n",
      "Epoch 8/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m563s\u001B[0m 180ms/step - accuracy: 0.8673 - loss: 0.3187 - val_accuracy: 0.7299 - val_loss: 0.8079\n",
      "Epoch 9/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m619s\u001B[0m 179ms/step - accuracy: 0.8811 - loss: 0.2873 - val_accuracy: 0.7277 - val_loss: 0.8569\n",
      "Epoch 10/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m564s\u001B[0m 180ms/step - accuracy: 0.8915 - loss: 0.2613 - val_accuracy: 0.7240 - val_loss: 0.9396\n",
      "Epoch 11/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m618s\u001B[0m 179ms/step - accuracy: 0.9057 - loss: 0.2325 - val_accuracy: 0.7173 - val_loss: 0.9803\n",
      "Epoch 12/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m567s\u001B[0m 181ms/step - accuracy: 0.9145 - loss: 0.2137 - val_accuracy: 0.7172 - val_loss: 1.0712\n",
      "Epoch 13/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m561s\u001B[0m 180ms/step - accuracy: 0.9246 - loss: 0.1906 - val_accuracy: 0.7178 - val_loss: 1.1356\n",
      "Epoch 14/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m575s\u001B[0m 184ms/step - accuracy: 0.9304 - loss: 0.1758 - val_accuracy: 0.7133 - val_loss: 1.1722\n",
      "Epoch 15/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m576s\u001B[0m 185ms/step - accuracy: 0.9356 - loss: 0.1646 - val_accuracy: 0.7086 - val_loss: 1.2242\n",
      "\u001B[1m976/976\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 34ms/step\n",
      "Confusion Matrix - GRU\n",
      "[[ 4394  2290   185]\n",
      " [ 1823 12183  1910]\n",
      " [  225  2565  5637]]\n",
      "Classification Report - GRU\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66      6869\n",
      "           1       0.72      0.77      0.74     15916\n",
      "           2       0.73      0.67      0.70      8427\n",
      "\n",
      "    accuracy                           0.71     31212\n",
      "   macro avg       0.71      0.69      0.70     31212\n",
      "weighted avg       0.71      0.71      0.71     31212\n",
      "\n",
      "Weighted F1 Score - GRU: 0.7107\n",
      "Best model is RNN with a weighted F1 score of 0.7223\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#With Preprocessing"
   ],
   "metadata": {
    "id": "dc62-lntPyij"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_text(text):\n",
    "    # Eliminar caracteres especiales y números\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    # Eliminar stopwords\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lematización\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Rejuntar las palabras en una frase\n",
    "    return ' '.join(words)"
   ],
   "metadata": {
    "id": "9UFA8KzGYUP1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Cargar el dataset desde un archivo .tsv\n",
    "data = pd.read_csv('train.tsv', sep='\\t')\n",
    "\n",
    "# Rellenar valores faltantes con un string vacío\n",
    "data['Phrase'] = data['Phrase'].fillna('')\n",
    "\n",
    "data['Sentiment'] = data['Sentiment'].apply(simplify_sentiment)\n",
    "\n",
    "# Preprocesamiento del texto\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Aplicar preprocesamiento\n",
    "data['Processed_Phrase'] = data['Phrase'].apply(preprocess_text)\n",
    "\n",
    "# Separar datos en características y etiquetas\n",
    "X = data['Processed_Phrase']\n",
    "y = data['Sentiment']\n",
    "\n",
    "# Codificación de etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Tokenizar y preparar las secuencias\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_sequences = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(X_sequences, maxlen=100)\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba (estratificado)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=13)\n",
    "for train_index, test_index in sss.split(X_padded, y):\n",
    "    X_train, X_test = X_padded[train_index], X_padded[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Implementación de Naive Bayes con preprocesamiento\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Crear el pipeline para el modelo de Naive Bayes\n",
    "naive_model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba para Naive Bayes\n",
    "X_train_nb, X_test_nb, y_train_nb, y_test_nb = train_test_split(X, y, test_size=0.2, random_state=13, stratify=y)\n",
    "\n",
    "# Entrenar el modelo Naive Bayes\n",
    "naive_model.fit(X_train_nb, y_train_nb)\n",
    "\n",
    "# Generar predicciones\n",
    "y_pred_nb = naive_model.predict(X_test_nb)\n",
    "\n",
    "# Evaluar el modelo Naive Bayes\n",
    "print(f\"Confusion Matrix - Naive Bayes\")\n",
    "print(confusion_matrix(y_test_nb, y_pred_nb))\n",
    "print(f\"Classification Report - Naive Bayes\")\n",
    "print(classification_report(y_test_nb, y_pred_nb))\n",
    "\n",
    "# Calcular F1 Score para Naive Bayes\n",
    "nb_f1 = f1_score(y_test_nb, y_pred_nb, average='weighted')\n",
    "print(f\"Weighted F1 Score - Naive Bayes: {nb_f1:.4f}\")\n",
    "\n",
    "# Entrenar y comparar los modelos\n",
    "rnn_f1 = create_and_train_rnn_model('RNN', X_train, y_train, X_test, y_test)\n",
    "lstm_f1 = create_and_train_rnn_model('LSTM', X_train, y_train, X_test, y_test)\n",
    "gru_f1 = create_and_train_rnn_model('GRU', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Comparar resultados\n",
    "results = {\n",
    "    \"RNN\": rnn_f1,\n",
    "    \"LSTM\": lstm_f1,\n",
    "    \"GRU\": gru_f1,\n",
    "    \"Naive Bayes\": nb_f1\n",
    "}\n",
    "\n",
    "best_model = max(results, key=results.get)\n",
    "print(f\"Best model is {best_model} with a weighted F1 score of {results[best_model]:.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSLlKqFAPTcU",
    "outputId": "ffeebf79-5d94-4449-88b4-5fc920f612be"
   },
   "execution_count": null,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - Naive Bayes\n",
      "[[ 4058  2401   410]\n",
      " [ 1711 11854  2351]\n",
      " [  330  2518  5579]]\n",
      "Classification Report - Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.59      0.63      6869\n",
      "           1       0.71      0.74      0.73     15916\n",
      "           2       0.67      0.66      0.67      8427\n",
      "\n",
      "    accuracy                           0.69     31212\n",
      "   macro avg       0.68      0.67      0.67     31212\n",
      "weighted avg       0.69      0.69      0.69     31212\n",
      "\n",
      "Weighted F1 Score - Naive Bayes: 0.6872\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m206s\u001B[0m 65ms/step - accuracy: 0.6159 - loss: 0.8622 - val_accuracy: 0.7133 - val_loss: 0.7055\n",
      "Epoch 2/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m273s\u001B[0m 69ms/step - accuracy: 0.7392 - loss: 0.6505 - val_accuracy: 0.7231 - val_loss: 0.6831\n",
      "Epoch 3/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m257s\u001B[0m 67ms/step - accuracy: 0.7672 - loss: 0.5766 - val_accuracy: 0.7286 - val_loss: 0.6858\n",
      "Epoch 4/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m205s\u001B[0m 66ms/step - accuracy: 0.7786 - loss: 0.5472 - val_accuracy: 0.7273 - val_loss: 0.6954\n",
      "Epoch 5/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m264s\u001B[0m 66ms/step - accuracy: 0.7944 - loss: 0.5089 - val_accuracy: 0.7243 - val_loss: 0.6991\n",
      "Epoch 6/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m256s\u001B[0m 65ms/step - accuracy: 0.8041 - loss: 0.4805 - val_accuracy: 0.7234 - val_loss: 0.7068\n",
      "Epoch 7/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m203s\u001B[0m 65ms/step - accuracy: 0.8106 - loss: 0.4608 - val_accuracy: 0.7281 - val_loss: 0.7283\n",
      "Epoch 8/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m201s\u001B[0m 65ms/step - accuracy: 0.8145 - loss: 0.4480 - val_accuracy: 0.7208 - val_loss: 0.7329\n",
      "Epoch 9/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m202s\u001B[0m 64ms/step - accuracy: 0.8208 - loss: 0.4312 - val_accuracy: 0.7252 - val_loss: 0.7579\n",
      "Epoch 10/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m201s\u001B[0m 64ms/step - accuracy: 0.8283 - loss: 0.4137 - val_accuracy: 0.7237 - val_loss: 0.7827\n",
      "Epoch 11/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m200s\u001B[0m 64ms/step - accuracy: 0.8331 - loss: 0.3976 - val_accuracy: 0.7209 - val_loss: 0.7790\n",
      "Epoch 12/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m203s\u001B[0m 64ms/step - accuracy: 0.8352 - loss: 0.3896 - val_accuracy: 0.7218 - val_loss: 0.8086\n",
      "Epoch 13/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m204s\u001B[0m 65ms/step - accuracy: 0.8422 - loss: 0.3761 - val_accuracy: 0.7196 - val_loss: 0.8168\n",
      "Epoch 14/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m200s\u001B[0m 64ms/step - accuracy: 0.8415 - loss: 0.3763 - val_accuracy: 0.7192 - val_loss: 0.7678\n",
      "Epoch 15/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m201s\u001B[0m 65ms/step - accuracy: 0.8328 - loss: 0.4087 - val_accuracy: 0.7186 - val_loss: 0.8173\n",
      "\u001B[1m976/976\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 15ms/step\n",
      "Confusion Matrix - RNN\n",
      "[[ 4286  2279   304]\n",
      " [ 1524 12478  1914]\n",
      " [  205  2357  5865]]\n",
      "Classification Report - RNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.67      6869\n",
      "           1       0.73      0.78      0.76     15916\n",
      "           2       0.73      0.70      0.71      8427\n",
      "\n",
      "    accuracy                           0.73     31212\n",
      "   macro avg       0.72      0.70      0.71     31212\n",
      "weighted avg       0.72      0.73      0.72     31212\n",
      "\n",
      "Weighted F1 Score - RNN: 0.7235\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m645s\u001B[0m 206ms/step - accuracy: 0.6376 - loss: 0.8279 - val_accuracy: 0.7189 - val_loss: 0.6824\n",
      "Epoch 2/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m688s\u001B[0m 208ms/step - accuracy: 0.7504 - loss: 0.6106 - val_accuracy: 0.7299 - val_loss: 0.6652\n",
      "Epoch 3/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m724s\u001B[0m 221ms/step - accuracy: 0.7787 - loss: 0.5403 - val_accuracy: 0.7365 - val_loss: 0.6630\n",
      "Epoch 4/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m702s\u001B[0m 208ms/step - accuracy: 0.7951 - loss: 0.4923 - val_accuracy: 0.7355 - val_loss: 0.6792\n",
      "Epoch 5/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m681s\u001B[0m 208ms/step - accuracy: 0.8098 - loss: 0.4545 - val_accuracy: 0.7335 - val_loss: 0.7093\n",
      "Epoch 6/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m656s\u001B[0m 210ms/step - accuracy: 0.8196 - loss: 0.4243 - val_accuracy: 0.7296 - val_loss: 0.7368\n",
      "Epoch 7/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m721s\u001B[0m 223ms/step - accuracy: 0.8288 - loss: 0.3995 - val_accuracy: 0.7275 - val_loss: 0.7724\n",
      "Epoch 8/15\n",
      "\u001B[1m3122/3122\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m709s\u001B[0m 212ms/step - accuracy: 0.8366 - loss: 0.3763 - val_accuracy: 0.7228 - val_loss: 0.8140\n",
      "Epoch 9/15\n",
      "\u001B[1m 809/3122\u001B[0m \u001B[32m━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━\u001B[0m \u001B[1m7:31\u001B[0m 195ms/step - accuracy: 0.8524 - loss: 0.3365"
     ]
    }
   ]
  }
 ]
}
