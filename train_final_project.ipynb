{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Descargar stopwords de NLTK si no las tienes\n",
    "print(\"Descargando stopwords de NLTK...\")\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Función para limpiar las letras\n",
    "def limpiar_texto(text):\n",
    "    text = text.lower()  # Convertir a minúsculas\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])  # Quitar puntuación\n",
    "    tokens = text.split()  # Tokenización\n",
    "    text = ' '.join([word for word in tokens if word not in stopwords.words('english')])  # Quitar stopwords\n",
    "    return text\n",
    "\n",
    "# Cargar la base de datos\n",
    "print(\"Cargando la base de datos...\")\n",
    "df = pd.read_csv('tcc_ceds_music.csv')\n",
    "\n",
    "# Tomar una muestra del 10% del dataset\n",
    "# print(\"Tomando una muestra del 10% del dataset...\")\n",
    "# df_sample = df.sample(frac=0.1, random_state=42)\n",
    "\n",
    "print(\"Mostrando las primeras filas del dataset:\")\n",
    "print(df.head())  # Para verificar que los datos se cargaron correctamente\n",
    "\n",
    "# Limpiar las letras\n",
    "print(\"Limpiando las letras...\")\n",
    "df['cleaned_lyrics'] = df['lyrics'].apply(limpiar_texto)\n",
    "\n",
    "# Vectorización usando TF-IDF\n",
    "print(\"Vectorizando las letras con TF-IDF...\")\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df['cleaned_lyrics']).toarray()\n",
    "\n",
    "print(\"Mostrando la forma del conjunto de características (X):\", X.shape)\n",
    "\n",
    "# Etiquetas de género\n",
    "print(\"Extrayendo las etiquetas de género...\")\n",
    "y = df['genre']\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "print(\"Dividiendo el conjunto de datos en entrenamiento y prueba...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Conjunto de entrenamiento y prueba preparado.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.32      0.11      0.16       926\n",
      "     country       0.46      0.54      0.50      1123\n",
      "     hip hop       0.53      0.20      0.29       198\n",
      "        jazz       0.48      0.13      0.20       731\n",
      "         pop       0.31      0.71      0.43      1398\n",
      "      reggae       0.69      0.21      0.32       515\n",
      "        rock       0.33      0.15      0.21       784\n",
      "\n",
      "    accuracy                           0.36      5675\n",
      "   macro avg       0.44      0.29      0.30      5675\n",
      "weighted avg       0.41      0.36      0.32      5675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo Naive Bayes\n",
    "modelo_nb = MultinomialNB()\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_nb.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = modelo_nb.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Crear un modelo de red neuronal con ajustes\n",
    "modelo_mlp_mejorado = MLPClassifier(hidden_layer_sizes=(256, 128, 64), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_mlp_mejorado.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_mlp_mejorado = modelo_mlp_mejorado.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"MLPClassifier Mejorado:\")\n",
    "print(classification_report(y_test, y_pred_mlp_mejorado))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Crear un modelo de Random Forest\n",
    "modelo_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_rf = modelo_rf.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Crear un modelo de regresión logística\n",
    "modelo_lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_lr.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_lr = modelo_lr.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Logistic Regression:\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Crear un modelo de SVM\n",
    "modelo_svm = SVC(kernel='linear')\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_svm.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_svm = modelo_svm.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Support Vector Machine (SVM):\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Crear un modelo de Gradient Boosting\n",
    "modelo_gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_gb.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_gb = modelo_gb.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Gradient Boosting Classifier:\")\n",
    "print(classification_report(y_test, y_pred_gb))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n"
     ]
    }
   ],
   "source": [
    "def predecir_genero(nuevas_letras):\n",
    "    nuevas_letras_limpias = limpiar_texto(nuevas_letras)\n",
    "    letras_vectorizadas = tfidf.transform([nuevas_letras_limpias]).toarray()\n",
    "    prediccion = modelo_nb.predict(letras_vectorizadas)\n",
    "    return prediccion[0]\n",
    "\n",
    "# Ejemplo de uso\n",
    "nueva_lyrics = \"Here goes the lyrics of the new song\"\n",
    "print(predecir_genero(nueva_lyrics))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "['vectorizer_tfidf.pkl']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "joblib.dump(modelo_nb, 'modelo_naive_bayes.pkl')\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "joblib.dump(modelo_nb, 'modelo_mlp.pkl')\n",
    "\n",
    "# Guardar el vectorizador TF-IDF\n",
    "joblib.dump(tfidf, 'vectorizer_tfidf.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
